align = c("l", "c", "c")
) %>%
kable_styling(full_width = FALSE, position = "center")
library(fairness)
# Filter only African-American and Caucasian individuals
compas_subset <- compas[compas$race %in% c("African-American", "Caucasian"), ]
# Create predicted probability column (between 0 and 1)
compas_subset$probs <- compas_subset$decile_score / 10
# Ensure race is a factor with "Caucasian" as the reference level
compas_subset$race <- factor(compas_subset$race, levels = c("Caucasian", "African-American"))
# Compute fairness metrics with cutoff = 0.5
acc <- acc_parity(data = compas_subset, outcome = "is_recid",
probs = "probs", group = "race", cutoff = 0.5)
dem <- dem_parity(data = compas_subset, outcome = "is_recid",
probs = "probs", group = "race", cutoff = 0.5)
eo <- equal_odds(data = compas_subset, outcome = "is_recid",
probs = "probs", group = "race", cutoff = 0.5)
suff <- pred_rate_parity(data = compas_subset, outcome = "is_recid",
probs = "probs", group = "race", cutoff = 0.5)
# Display the results
acc
dem
eo
suff
knitr::opts_chunk$set(
echo = FALSE,          # Oculta el código por defecto
message = FALSE,       # Oculta mensajes como los de carga de paquetes
warning = FALSE,       # Oculta advertencias
fig.width = 5,         # Ancho por defecto de las figuras
fig.height = 3,        # Alto por defecto
fig.align = "center"   # Centra los gráficos
)
compas <- read.csv("compas-scores-two-years.csv")
n_original <- nrow(compas)
compas_filtered <- compas %>%
filter(days_b_screening_arrest >= -30 & days_b_screening_arrest <= 30)
n_filtered <- nrow(compas_filtered)
cat("Original rows:", n_original, "\n")
cat("Filtered rows (between -30 and 30):", n_filtered, "\n")
compas_slices <- compas_filtered %>%
filter(race %in% c("African-American", "Caucasian"))
sufficiency_df <- compas_slices %>%
group_by(race, decile_score) %>%
summarise(p_y_given_r = mean(two_year_recid == 1), .groups = "drop")
ggplot(sufficiency_df, aes(x = decile_score, y = p_y_given_r, color = race)) +
geom_line(size = 1.2) +
geom_point(size = 2.2) +
scale_x_continuous(breaks = 1:10) +
scale_color_manual(values = c("African-American" = "#E41A1C",
"Caucasian" = "#377EB8")) +
labs(title = "Sufficiency: P(Y = 1 | R = r, A)",
x = "Risk Score (decile_score)",
y = "P(recidivism | score)",
color = "Race") +
theme_minimal()
library(pROC)
compas_roc <- compas_filtered %>%
filter(race %in% c("African-American", "Caucasian")) %>%
mutate(prob_score = decile_score / 10)  # proxy de probabilidad
african <- compas_roc %>% filter(race == "African-American")
caucasian <- compas_roc %>% filter(race == "Caucasian")
roc_african <- roc(african$two_year_recid, african$prob_score)
roc_caucasian <- roc(caucasian$two_year_recid, caucasian$prob_score)
plot(roc_african, col = "red", lwd = 2, main = "ROC Curve by Race")
plot(roc_caucasian, col = "blue", lwd = 2, add = TRUE)
legend("bottomright", legend = c("African-American", "Caucasian"), col = c("red", "blue"), lwd = 2)
get_rates <- function(data, threshold) {
pred <- ifelse(data$prob_score >= threshold, 1, 0)
TP <- sum(pred == 1 & data$two_year_recid == 1)
FP <- sum(pred == 1 & data$two_year_recid == 0)
FN <- sum(pred == 0 & data$two_year_recid == 1)
TN <- sum(pred == 0 & data$two_year_recid == 0)
TPR <- if ((TP + FN) == 0) NA else TP / (TP + FN)
FPR <- if ((FP + TN) == 0) NA else FP / (FP + TN)
PPV <- if ((TP + FP) == 0) NA else TP / (TP + FP)
return(list(TPR = TPR, FPR = FPR, PPV = PPV))
}
thresholds <- seq(0.3, 0.8, by = 0.01)
grid <- expand.grid(th_african = thresholds, th_caucasian = thresholds)
grid$TPR_African <- NA
grid$FPR_African <- NA
grid$PPV_African <- NA
grid$TPR_Caucasian <- NA
grid$FPR_Caucasian <- NA
grid$PPV_Caucasian <- NA
for (i in 1:nrow(grid)) {
th_af <- grid$th_african[i]
th_ca <- grid$th_caucasian[i]
rates_af <- get_rates(african, th_af)
rates_ca <- get_rates(caucasian, th_ca)
grid$TPR_African[i] <- rates_af$TPR
grid$FPR_African[i] <- rates_af$FPR
grid$PPV_African[i] <- rates_af$PPV
grid$TPR_Caucasian[i] <- rates_ca$TPR
grid$FPR_Caucasian[i] <- rates_ca$FPR
grid$PPV_Caucasian[i] <- rates_ca$PPV
}
filtered <- subset(grid,
abs(TPR_African - TPR_Caucasian) <= 0.01 &
abs(FPR_African - FPR_Caucasian) <= 0.01)
filtered_results <- filtered[order(-(filtered$TPR_African + filtered$TPR_Caucasian)), ]
best_pair <- head(filtered_results, 1)
best_pair <- transform(best_pair,
th_african = round(th_african, 3),
th_caucasian = round(th_caucasian, 3),
TPR_African = round(TPR_African, 3),
FPR_African = round(FPR_African, 3),
PPV_African = round(PPV_African, 3),
TPR_Caucasian = round(TPR_Caucasian, 3),
FPR_Caucasian = round(FPR_Caucasian, 3),
PPV_Caucasian = round(PPV_Caucasian, 3))
knitr::kable(best_pair, caption = "Best threshold pair with equalized TPR and FPR (within 1%)")
compas_age_groups <- compas_filtered %>%
mutate(age_group = case_when(
age <= 25 ~ "25 or younger",
age >= 50 ~ "50 or older",
TRUE ~ "Other"
)) %>%
filter(age_group %in% c("25 or younger", "50 or older"))  # Solo grupos relevantes
recid_by_age <- compas_age_groups %>%
group_by(age_group) %>%
summarise(recidivism_rate = mean(two_year_recid == 1), count = n())
recid_by_age %>%
mutate(
recidivism_rate = round(recidivism_rate, 3)
) %>%
kable(
caption = "Recidivism rate by age group",
col.names = c("Age Group", "Recidivism Rate", "Count"),
align = c("l", "c", "c")
) %>%
kable_styling(full_width = FALSE, position = "center")
library(fairness)
# Filter only African-American and Caucasian individuals
compas_subset <- compas[compas$race %in% c("African-American", "Caucasian"), ]
# Create predicted probability column (between 0 and 1)
compas_subset$probs <- compas_subset$decile_score / 10
# Ensure race is a factor with "Caucasian" as the reference level
compas_subset$race <- factor(compas_subset$race, levels = c("Caucasian", "African-American"))
# Compute fairness metrics with cutoff = 0.5
acc <- acc_parity(data = compas_subset, outcome = "is_recid",
probs = "probs", group = "race", cutoff = 0.5)
dem <- dem_parity(data = compas_subset, outcome = "is_recid",
probs = "probs", group = "race", cutoff = 0.5)
eo <- equal_odds(data = compas_subset, outcome = "is_recid",
probs = "probs", group = "race", cutoff = 0.5)
suff <- pred_rate_parity(data = compas_subset, outcome = "is_recid",
probs = "probs", group = "race", cutoff = 0.5)
# Display the results
acc
dem
eo
suff
knitr::opts_chunk$set(
echo = FALSE,
message = FALSE,
warning = FALSE,
fig.width = 5,
fig.height = 3,
fig.align = "center"
)
library(dplyr)
library(ggplot2)
library(reshape2)
library(plotly)
library(fairness)
library(kableExtra)
library(knitr)
library(purrr)
compas <- read.csv("compas-scores-two-years.csv")
n_original <- nrow(compas)
compas_filtered <- compas %>%
filter(days_b_screening_arrest >= -30 & days_b_screening_arrest <= 30)
n_filtered <- nrow(compas_filtered)
cat("Original rows:", n_original, "\n")
cat("Filtered rows (between -30 and 30):", n_filtered, "\n")
compas_slices <- compas_filtered %>%
filter(race %in% c("African-American", "Caucasian"))
sufficiency_df <- compas_slices %>%
group_by(race, decile_score) %>%
summarise(p_y_given_r = mean(two_year_recid == 1), .groups = "drop")
ggplot(sufficiency_df, aes(x = decile_score, y = p_y_given_r, color = race)) +
geom_line(size = 1.2) +
geom_point(size = 2.2) +
scale_x_continuous(breaks = 1:10) +
scale_color_manual(values = c("African-American" = "#E41A1C",
"Caucasian" = "#377EB8")) +
labs(title = "Sufficiency: P(Y = 1 | R = r, A)",
x = "Risk Score (decile_score)",
y = "P(recidivism | score)",
color = "Race") +
theme_minimal()
library(pROC)
compas_roc <- compas_filtered %>%
filter(race %in% c("African-American", "Caucasian")) %>%
mutate(prob_score = decile_score / 10)  # proxy de probabilidad
african <- compas_roc %>% filter(race == "African-American")
caucasian <- compas_roc %>% filter(race == "Caucasian")
roc_african <- roc(african$two_year_recid, african$prob_score)
roc_caucasian <- roc(caucasian$two_year_recid, caucasian$prob_score)
plot(roc_african, col = "red", lwd = 2, main = "ROC Curve by Race")
plot(roc_caucasian, col = "blue", lwd = 2, add = TRUE)
legend("bottomright", legend = c("African-American", "Caucasian"), col = c("red", "blue"), lwd = 2)
get_rates <- function(data, threshold) {
pred <- ifelse(data$prob_score >= threshold, 1, 0)
TP <- sum(pred == 1 & data$two_year_recid == 1)
FP <- sum(pred == 1 & data$two_year_recid == 0)
FN <- sum(pred == 0 & data$two_year_recid == 1)
TN <- sum(pred == 0 & data$two_year_recid == 0)
TPR <- if ((TP + FN) == 0) NA else TP / (TP + FN)
FPR <- if ((FP + TN) == 0) NA else FP / (FP + TN)
PPV <- if ((TP + FP) == 0) NA else TP / (TP + FP)
return(list(TPR = TPR, FPR = FPR, PPV = PPV))
}
thresholds <- seq(0.3, 0.8, by = 0.01)
grid <- expand.grid(th_african = thresholds, th_caucasian = thresholds)
grid$TPR_African <- NA
grid$FPR_African <- NA
grid$PPV_African <- NA
grid$TPR_Caucasian <- NA
grid$FPR_Caucasian <- NA
grid$PPV_Caucasian <- NA
for (i in 1:nrow(grid)) {
th_af <- grid$th_african[i]
th_ca <- grid$th_caucasian[i]
rates_af <- get_rates(african, th_af)
rates_ca <- get_rates(caucasian, th_ca)
grid$TPR_African[i] <- rates_af$TPR
grid$FPR_African[i] <- rates_af$FPR
grid$PPV_African[i] <- rates_af$PPV
grid$TPR_Caucasian[i] <- rates_ca$TPR
grid$FPR_Caucasian[i] <- rates_ca$FPR
grid$PPV_Caucasian[i] <- rates_ca$PPV
}
filtered <- subset(grid,
abs(TPR_African - TPR_Caucasian) <= 0.01 &
abs(FPR_African - FPR_Caucasian) <= 0.01)
filtered_results <- filtered[order(-(filtered$TPR_African + filtered$TPR_Caucasian)), ]
best_pair <- head(filtered_results, 1)
best_pair <- transform(best_pair,
th_african = round(th_african, 3),
th_caucasian = round(th_caucasian, 3),
TPR_African = round(TPR_African, 3),
FPR_African = round(FPR_African, 3),
PPV_African = round(PPV_African, 3),
TPR_Caucasian = round(TPR_Caucasian, 3),
FPR_Caucasian = round(FPR_Caucasian, 3),
PPV_Caucasian = round(PPV_Caucasian, 3))
knitr::kable(best_pair, caption = "Best threshold pair with equalized TPR and FPR (within 1%)")
compas_age_groups <- compas_filtered %>%
mutate(age_group = case_when(
age <= 25 ~ "25 or younger",
age >= 50 ~ "50 or older",
TRUE ~ "Other"
)) %>%
filter(age_group %in% c("25 or younger", "50 or older"))  # Solo grupos relevantes
recid_by_age <- compas_age_groups %>%
group_by(age_group) %>%
summarise(recidivism_rate = mean(two_year_recid == 1), count = n())
recid_by_age %>%
mutate(
recidivism_rate = round(recidivism_rate, 3)
) %>%
kable(
caption = "Recidivism rate by age group",
col.names = c("Age Group", "Recidivism Rate", "Count"),
align = c("l", "c", "c")
) %>%
kable_styling(full_width = FALSE, position = "center")
library(fairness)
# Filter only African-American and Caucasian individuals
compas_subset <- compas[compas$race %in% c("African-American", "Caucasian"), ]
# Create predicted probability column (between 0 and 1)
compas_subset$probs <- compas_subset$decile_score / 10
# Ensure race is a factor with "Caucasian" as the reference level
compas_subset$race <- factor(compas_subset$race, levels = c("Caucasian", "African-American"))
# Compute fairness metrics with cutoff = 0.5
acc <- acc_parity(data = compas_subset, outcome = "is_recid",
probs = "probs", group = "race", cutoff = 0.5)
dem <- dem_parity(data = compas_subset, outcome = "is_recid",
probs = "probs", group = "race", cutoff = 0.5)
eo <- equal_odds(data = compas_subset, outcome = "is_recid",
probs = "probs", group = "race", cutoff = 0.5)
suff <- pred_rate_parity(data = compas_subset, outcome = "is_recid",
probs = "probs", group = "race", cutoff = 0.5)
# Display the results
acc
dem
eo
suff
setwd("C:/Users/serto/OneDrive/Escritorio/segundo cuatri/Edm/Tareas/Task XAI3/Task XAI3")
knitr::opts_chunk$set(echo = TRUE)
library(randomForest)
library(ggplot2)
library(dplyr)
library(pdp)
data_day <- read.csv("day.csv")
data_day$spring <- as.integer(data_day$season == 2)
data_day$summer <- as.integer(data_day$season == 3)
data_day$fall <- as.integer(data_day$season == 4)
data_day$MISTY <- as.integer(data_day$weathersit == 2)
data_day$RAIN <- as.integer(data_day$weathersit %in% c(3, 4))
data_day$temp <- data_day$temp * 47 - 8
data_day$hum <- data_day$hum * 100
data_day$windspeed <- data_day$windspeed * 67
data_day$days_from_start <- as.numeric(as.Date(data_day$dteday) - as.Date("2011-01-01"))
features <- data_day[, c("spring", "summer", "fall", "MISTY", "RAIN", "temp", "hum", "windspeed", "days_from_start", "workingday", "holiday", "cnt")]
set.seed(42)
model_rf <- randomForest(cnt ~ workingday + holiday + spring + summer + fall + MISTY + RAIN + temp + hum + windspeed + days_from_start, data = features, ntree = 500)
pdp_day <- partial(model_rf, pred.var = "days_from_start")
pdp_temperature <- partial(model_rf, pred.var = "temp")
pdp_humidity <- partial(model_rf, pred.var = "hum")
pdp_wind <- partial(model_rf, pred.var = "windspeed")
autoplot(pdp_day) + ggtitle("PDP – Days from 2011")
autoplot(pdp_temperature) + ggtitle("PDP – Temperature")
autoplot(pdp_humidity) + ggtitle("PDP – Humidity")
autoplot(pdp_wind) + ggtitle("PDP – Wind Speed")
knitr::opts_chunk$set(echo = TRUE)
library(randomForest)
library(ggplot2)
library(dplyr)
library(pdp)
data_day <- read.csv("day.csv")
data_day$spring <- as.integer(data_day$season == 2)
data_day$summer <- as.integer(data_day$season == 3)
data_day$fall <- as.integer(data_day$season == 4)
data_day$MISTY <- as.integer(data_day$weathersit == 2)
data_day$RAIN <- as.integer(data_day$weathersit %in% c(3, 4))
data_day$temp <- data_day$temp * 47 - 8
data_day$hum <- data_day$hum * 100
data_day$windspeed <- data_day$windspeed * 67
data_day$days_from_start <- as.numeric(as.Date(data_day$dteday) - as.Date("2011-01-01"))
features <- data_day[, c("spring", "summer", "fall", "MISTY", "RAIN", "temp", "hum", "windspeed", "days_from_start", "workingday", "holiday", "cnt")]
set.seed(42)
model_rf <- randomForest(cnt ~ workingday + holiday + spring + summer + fall + MISTY + RAIN + temp + hum + windspeed + days_from_start, data = features, ntree = 500)
pdp_day <- partial(model_rf, pred.var = "days_from_start")
pdp_temperature <- partial(model_rf, pred.var = "temp")
pdp_humidity <- partial(model_rf, pred.var = "hum")
pdp_wind <- partial(model_rf, pred.var = "windspeed")
autoplot(pdp_day) + ggtitle("PDP – Days from 2011")
autoplot(pdp_temperature) + ggtitle("PDP – Temperature")
autoplot(pdp_humidity) + ggtitle("PDP – Humidity")
autoplot(pdp_wind) + ggtitle("PDP – Wind Speed")
library(randomForest)
library(ggplot2)
library(dplyr)
library(pdp)
set.seed(42)
subset_sample <- features %>% sample_n(500, replace = TRUE)
model_rf_2d <- randomForest(cnt ~ hum + temp, data = subset_sample)
pdp_2d <- partial(model_rf_2d, pred.var = c("hum", "temp"), grid.resolution = 50, chull = TRUE)
h_range <- range(pdp_2d$hum)
t_range <- range(pdp_2d$temp)
tile_w <- diff(h_range) / 49
tile_h <- diff(t_range) / 49
ggplot() +
geom_tile(data = pdp_2d, aes(x = hum, y = temp, fill = yhat), width = tile_w, height = tile_h) +
geom_density2d(data = subset_sample, aes(x = hum, y = temp), color = "white", size = 0.3) +
scale_fill_viridis_c() +
labs(title = "2D PDP with Density Overlay",
x = "Humidity",
y = "Temperature",
fill = "Predicted Count") +
theme_minimal()
```{r setup, include=FALSE}
knitr::opts_chunk$set(
warning = FALSE,
message = FALSE,
echo = TRUE,
results = "hide"
)
knitr::opts_chunk$set(echo = TRUE)
library(randomForest)
library(ggplot2)
library(dplyr)
library(pdp)
data_day <- read.csv("day.csv")
data_day$spring <- as.integer(data_day$season == 2)
data_day$summer <- as.integer(data_day$season == 3)
data_day$fall <- as.integer(data_day$season == 4)
data_day$MISTY <- as.integer(data_day$weathersit == 2)
data_day$RAIN <- as.integer(data_day$weathersit %in% c(3, 4))
data_day$temp <- data_day$temp * 47 - 8
data_day$hum <- data_day$hum * 100
data_day$windspeed <- data_day$windspeed * 67
data_day$days_from_start <- as.numeric(as.Date(data_day$dteday) - as.Date("2011-01-01"))
features <- data_day[, c("spring", "summer", "fall", "MISTY", "RAIN", "temp", "hum", "windspeed", "days_from_start", "workingday", "holiday", "cnt")]
set.seed(42)
model_rf <- randomForest(cnt ~ workingday + holiday + spring + summer + fall + MISTY + RAIN + temp + hum + windspeed + days_from_start, data = features, ntree = 500)
pdp_day <- partial(model_rf, pred.var = "days_from_start")
pdp_temperature <- partial(model_rf, pred.var = "temp")
pdp_humidity <- partial(model_rf, pred.var = "hum")
pdp_wind <- partial(model_rf, pred.var = "windspeed")
autoplot(pdp_day) + ggtitle("PDP – Days from 2011")
autoplot(pdp_temperature) + ggtitle("PDP – Temperature")
autoplot(pdp_humidity) + ggtitle("PDP – Humidity")
autoplot(pdp_wind) + ggtitle("PDP – Wind Speed")
library(randomForest)
library(ggplot2)
library(dplyr)
library(pdp)
set.seed(42)
subset_sample <- features %>% sample_n(500, replace = TRUE)
model_rf_2d <- randomForest(cnt ~ hum + temp, data = subset_sample)
pdp_2d <- partial(model_rf_2d, pred.var = c("hum", "temp"), grid.resolution = 50, chull = TRUE)
h_range <- range(pdp_2d$hum)
t_range <- range(pdp_2d$temp)
tile_w <- diff(h_range) / 49
tile_h <- diff(t_range) / 49
ggplot() +
geom_tile(data = pdp_2d, aes(x = hum, y = temp, fill = yhat), width = tile_w, height = tile_h) +
geom_density2d(data = subset_sample, aes(x = hum, y = temp), color = "white", size = 0.3) +
scale_fill_viridis_c() +
labs(title = "2D PDP with Density Overlay",
x = "Humidity",
y = "Temperature",
fill = "Predicted Count") +
theme_minimal()
knitr::opts_chunk$set(echo = TRUE)
library(randomForest)
library(ggplot2)
library(dplyr)
library(pdp)
data_day <- read.csv("day.csv")
data_day$spring <- as.integer(data_day$season == 2)
data_day$summer <- as.integer(data_day$season == 3)
data_day$fall <- as.integer(data_day$season == 4)
data_day$MISTY <- as.integer(data_day$weathersit == 2)
data_day$RAIN <- as.integer(data_day$weathersit %in% c(3, 4))
data_day$temp <- data_day$temp * 47 - 8
data_day$hum <- data_day$hum * 100
data_day$windspeed <- data_day$windspeed * 67
data_day$days_from_start <- as.numeric(as.Date(data_day$dteday) - as.Date("2011-01-01"))
features <- data_day[, c("spring", "summer", "fall", "MISTY", "RAIN", "temp", "hum", "windspeed", "days_from_start", "workingday", "holiday", "cnt")]
set.seed(42)
model_rf <- randomForest(cnt ~ workingday + holiday + spring + summer + fall + MISTY + RAIN + temp + hum + windspeed + days_from_start, data = features, ntree = 500)
pdp_day <- partial(model_rf, pred.var = "days_from_start")
pdp_temperature <- partial(model_rf, pred.var = "temp")
pdp_humidity <- partial(model_rf, pred.var = "hum")
pdp_wind <- partial(model_rf, pred.var = "windspeed")
autoplot(pdp_day) + ggtitle("PDP – Days from 2011")
autoplot(pdp_temperature) + ggtitle("PDP – Temperature")
autoplot(pdp_humidity) + ggtitle("PDP – Humidity")
autoplot(pdp_wind) + ggtitle("PDP – Wind Speed")
set.seed(42)
subset_sample <- features %>% sample_n(500, replace = TRUE)
model_rf_2d <- randomForest(cnt ~ hum + temp, data = subset_sample)
pdp_2d <- partial(model_rf_2d, pred.var = c("hum", "temp"), grid.resolution = 50, chull = TRUE)
h_range <- range(pdp_2d$hum)
knitr::opts_chunk$set(
warning = FALSE,
message = FALSE,
echo = TRUE,
results = "hide"
)
library(randomForest)
library(ggplot2)
library(dplyr)
library(pdp)
data_day <- read.csv("day.csv")
data_day$spring <- as.integer(data_day$season == 2)
data_day$summer <- as.integer(data_day$season == 3)
data_day$fall <- as.integer(data_day$season == 4)
data_day$MISTY <- as.integer(data_day$weathersit == 2)
data_day$RAIN <- as.integer(data_day$weathersit %in% c(3, 4))
data_day$temp <- data_day$temp * 47 - 8
data_day$hum <- data_day$hum * 100
data_day$windspeed <- data_day$windspeed * 67
data_day$days_from_start <- as.numeric(as.Date(data_day$dteday) - as.Date("2011-01-01"))
features <- data_day[, c("spring", "summer", "fall", "MISTY", "RAIN", "temp", "hum", "windspeed", "days_from_start", "workingday", "holiday", "cnt")]
set.seed(42)
model_rf <- randomForest(cnt ~ workingday + holiday + spring + summer + fall + MISTY + RAIN + temp + hum + windspeed + days_from_start, data = features, ntree = 500)
pdp_day <- partial(model_rf, pred.var = "days_from_start")
pdp_temperature <- partial(model_rf, pred.var = "temp")
pdp_humidity <- partial(model_rf, pred.var = "hum")
pdp_wind <- partial(model_rf, pred.var = "windspeed")
autoplot(pdp_day) + ggtitle("PDP – Days from 2011")
autoplot(pdp_temperature) + ggtitle("PDP – Temperature")
autoplot(pdp_humidity) + ggtitle("PDP – Humidity")
autoplot(pdp_wind) + ggtitle("PDP – Wind Speed")
set.seed(42)
subset_sample <- features %>% sample_n(500, replace = TRUE)
model_rf_2d <- randomForest(cnt ~ hum + temp, data = subset_sample)
pdp_2d <- partial(model_rf_2d, pred.var = c("hum", "temp"), grid.resolution = 50, chull = TRUE)
h_range <- range(pdp_2d$hum)
t_range <- range(pdp_2d$temp)
tile_w <- diff(h_range) / 49
tile_h <- diff(t_range) / 49
ggplot() +
geom_tile(data = pdp_2d, aes(x = hum, y = temp, fill = yhat), width = tile_w, height = tile_h) +
geom_density2d(data = subset_sample, aes(x = hum, y = temp), color = "white", size = 0.3) +
scale_fill_viridis_c() +
labs(title = "2D PDP with Density Overlay",
x = "Humidity",
y = "Temperature",
fill = "Predicted Count") +
theme_minimal()
housing <- read.csv("kc_house_data.csv")
set.seed(42)
housing_subset <- housing %>% sample_n(1000)
model_housing <- randomForest(price ~ bedrooms + bathrooms + sqft_living + sqft_lot + floors + yr_built, data = housing_subset)
variables <- c("bedrooms", "bathrooms", "sqft_living", "floors")
for (v in variables) {
pdp_result <- partial(model_housing, pred.var = v, chull = TRUE)
plot_pdp <- ggplot(pdp_result, aes_string(x = v, y = "yhat")) +
geom_line() +
labs(title = paste("PDP –", v),
x = v,
y = "Predicted Price") +
theme_minimal()
print(plot_pdp)
}
